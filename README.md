# Dual Model Employee Salary Predictor (Classification & Regression)

![Python](https://img.shields.io/badge/Python-3.9%2B-blue.svg) ![Streamlit](https://img.shields.io/badge/Streamlit-1.30%2B-red.svg) ![Scikit-learn](https://img.shields.io/badge/Scikit--learn-1.3%2B-orange.svg)

This project is an advanced web application built with Streamlit that performs two key predictive tasks:

1.  **Classification**: Predicts whether an employee's salary is `>50K` or `<=50K`.
2.  **Regression**: Predicts an *estimated numerical salary* for the employee.

The project stands out by implementing a sophisticated data imputation pipeline, leveraging tuned ensemble models, and integrating explainable AI (XAI) techniques for both prediction tasks into a polished, interactive, and high-performance interface.

## üöÄ Key Features

* **Dual Stacked Models**: Simultaneously trains and serves a **Stacking Classifier** and a **Stacking Regressor**. Each ensemble uses Random Forest and Gradient Boosting as base estimators for robust and accurate predictions.
* **Advanced Salary Imputation**: Since the source data lacks a numerical salary, this feature is engineered by training a preliminary `Ridge` regression model. This provides a more realistic, feature-driven salary estimate for the regression task than simple rule-based methods.
* **Hyperparameter Tuning**: Integrates `RandomizedSearchCV` directly into the training pipeline to automatically find optimized parameters for the base models, boosting the performance of the final stacked ensembles.
* **Dual Explainable AI (XAI)**: Utilizes `LIME` to generate local, instance-specific explanations for *both* the classification and regression models. This answers the crucial question: "Why did the models make this specific prediction?"
* **Performance Optimized**: Leverages Streamlit's caching (`@st.cache_resource` and `@st.cache_data`) to ensure that models and data are loaded only once, providing a fast and responsive user experience.
* **Interactive Web Interface**: A user-friendly application built with Streamlit, featuring tabs to clearly separate classifier and regressor insights, and a sidebar form (`st.form`) for efficient input.

## üß† How It Works

The application's core logic is built on a sophisticated dual-model system:

1.  **Advanced Salary Imputation**: A numerical `estimated_salary` feature is engineered by first training a preliminary `Ridge` regression model on the dataset's features. The output is then scaled to a realistic salary range, creating a high-quality target variable for the main regression model.
2.  **Feature Preprocessing**: The `fnlwgt` (final weight) column is removed, and categorical features are numerically encoded using `LabelEncoder`. Data is scaled using `StandardScaler` to prepare it for the models.
3.  **Tuned Ensemble Training**: Two separate stacked models are trained. During this process, `RandomizedSearchCV` tunes the hyperparameters of the base Random Forest and Gradient Boosting models before they are stacked, ensuring high performance.
4.  **Prediction & Dual Explanation**: When a user inputs data, it is preprocessed and fed to both the classifier and the regressor. The app displays the final predictions and uses `LIME` to generate easy-to-understand charts explaining the factors that influenced both the income bracket and the estimated salary.

## üõ†Ô∏è Technology Stack

* **Backend & ML**: Python, Scikit-learn, Pandas, NumPy, Joblib
* **Frontend / Web App**: Streamlit
* **Data Visualization**: Matplotlib, Plotly
* **Explainable AI**: LIME

## ‚öôÔ∏è Setup and Usage

1.  **Clone the repository:**
    ```bash
    git clone <your-repo-url>
    cd <your-repo-name>
    ```

2.  **Create and activate a virtual environment** (recommended):
    ```bash
    python -m venv venv
    # On Windows
    venv\Scripts\activate
    # On macOS/Linux
    source venv/bin/activate
    ```

3.  **Install the required libraries:**
    ```bash
    pip install streamlit pandas numpy scikit-learn joblib matplotlib plotly lime
    ```

4.  **Download the Dataset**: Ensure you have the `adult.csv` dataset in the same directory as the script.

5.  **Train the Models (First-Time Setup)**: Before running the app, you need to train the models. The app provides a button to do this, or you can run the following command in your terminal:
    ```bash
    streamlit run salary_app_dual_refined.py train
    ```
    This will create three files: `stacked_classifier_model_v4.pkl`, `stacked_regressor_model_v4.pkl`, and `preprocessor_dual_v4.pkl`.

6.  **Run the Application**:
    ```bash
    streamlit run salary_app_dual_refined.py
    ```
    The application will open in your web browser.

## ‚ö†Ô∏è Known Limitations & Disclaimer

* The **Predicted Estimated Salary** is derived from a regression model trained on data that was itself generated by a preliminary model. It is a sophisticated estimate but not a reflection of true, real-world salaries.
* As a result, there may be instances where the **Predicted Salary Bracket** (e.g., `<=50K`) and the **Predicted Estimated Salary** (e.g., `$54,000`) appear to contradict. This is an expected outcome, as the two models learn different patterns. The application will display a warning when such a contradiction occurs.
* **Global vs. Local Importance**: The LIME plots show which features were most important for *one specific prediction* (local importance). This may differ from the features that are most important *on average* for the model across all data (global importance).

## üîÆ Future Improvements

* **Explore Advanced XAI**: Integrate other explainability libraries like `SHAP` to provide alternative or more comprehensive (e.g., global) explanations.
* **More Complex Imputation**: Experiment with more complex models for the preliminary salary imputation step, such as a small neural network, to potentially capture more nuanced relationships.
* **CI/CD Pipeline**: Implement a CI/CD pipeline using GitHub Actions to automate testing and deployment.
* **Cloud Deployment**: Deploy the application on a permanent cloud service like Streamlit Community Cloud or Heroku for 24/7 availability.
